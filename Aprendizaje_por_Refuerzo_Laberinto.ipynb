{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiho/oceMYH2O12lv8dosb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Migatte-Yk/Aprendizaje_Por_Refuerzo_Laberinto/blob/main/Aprendizaje_por_Refuerzo_Laberinto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KpfoBi11hlDT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "5ef71123-ab07-4244-d73b-639e366c605a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-980ae4ee3850>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Validar movimiento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_valid_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mnew_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-980ae4ee3850>\u001b[0m in \u001b[0;36mis_valid_move\u001b[0;34m(maze, position)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Función para validar movimientos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_valid_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmaze\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmaze\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "\n",
        "def create_maze(size=100):\n",
        "    maze = np.zeros((size, size), dtype=int)\n",
        "    # Agregar obstáculos aleatorios\n",
        "    num_obstacles = int(size * size * 0.3)\n",
        "    for _ in range(num_obstacles):\n",
        "        x, y = np.random.randint(0, size, size=2)\n",
        "        maze[x, y] = 1\n",
        "\n",
        "    # Definir meta\n",
        "    goal_x, goal_y = np.random.randint(0, size, size=2)\n",
        "    maze[goal_x, goal_y] = 2\n",
        "    return maze, (goal_x, goal_y)\n",
        "\n",
        "# Generar el laberinto\n",
        "maze_size = 100\n",
        "maze, goal_position = create_maze(maze_size)\n",
        "\n",
        "# Parámetros del modelo\n",
        "alpha = 0.7  # Tasa de aprendizaje\n",
        "gamma = 0.9  # Factor de descuento\n",
        "epsilon = 1.0  # Parámetro de exploración\n",
        "epsilon_decay = 0.995\n",
        "min_epsilon = 0.1\n",
        "episodes = 1000\n",
        "\n",
        "# Acciones posibles: arriba, abajo, izquierda, derecha\n",
        "actions = [\"up\", \"down\", \"left\", \"right\"]\n",
        "action_map = {\n",
        "    \"up\": (-1, 0),\n",
        "    \"down\": (1, 0),\n",
        "    \"left\": (0, -1),\n",
        "    \"right\": (0, 1)\n",
        "}\n",
        "\n",
        "# Función para validar movimientos\n",
        "def is_valid_move(maze, position):\n",
        "    x, y = position\n",
        "    if 0 <= x < maze.shape[0] and 0 <= y < maze.shape[1]:\n",
        "        return maze[x, y] != 1\n",
        "    return False\n",
        "\n",
        "# Inicializar la tabla Q\n",
        "q_table = np.zeros((maze_size, maze_size, len(actions)))\n",
        "\n",
        "# Entrenamiento del agente\n",
        "for episode in range(episodes):\n",
        "    # Selección de un estado inicial\n",
        "    current_position = (np.random.randint(maze_size), np.random.randint(maze_size))\n",
        "    while maze[current_position] == 1 or maze[current_position] == 2:\n",
        "        current_position = (np.random.randint(maze_size), np.random.randint(maze_size))\n",
        "\n",
        "    # Episodio\n",
        "    done = False\n",
        "    while not done:\n",
        "        # Selección de acción (Exploración o Explotación)\n",
        "        if random.uniform(0, 1) < epsilon:\n",
        "            action_index = random.choice(range(len(actions)))\n",
        "        else:\n",
        "            action_index = np.argmax(q_table[current_position[0], current_position[1], :])\n",
        "\n",
        "        action = actions[action_index]\n",
        "        new_position = (\n",
        "            current_position[0] + action_map[action][0],\n",
        "            current_position[1] + action_map[action][1]\n",
        "        )\n",
        "\n",
        "        # Validar movimiento\n",
        "        if not is_valid_move(maze, new_position):\n",
        "            new_position = current_position\n",
        "\n",
        "        # Calcular recompensa\n",
        "        if new_position == goal_position:\n",
        "            reward = 100  # Gran recompensa por llegar a la meta\n",
        "            done = True\n",
        "        elif new_position == current_position:\n",
        "            reward = -10  # Penalización por quedarse en el mismo lugar\n",
        "        else:\n",
        "            reward = -1  # Penalización leve por movimiento regular\n",
        "\n",
        "        # Actualizar tabla Q\n",
        "        old_value = q_table[current_position[0], current_position[1], action_index]\n",
        "        next_max = np.max(q_table[new_position[0], new_position[1], :])\n",
        "        new_value = old_value + alpha * (reward + gamma * next_max - old_value)\n",
        "        q_table[current_position[0], current_position[1], action_index] = new_value\n",
        "\n",
        "        # Actualizar posición\n",
        "        current_position = new_position\n",
        "\n",
        "    # Reducir epsilon (menor exploración con el tiempo)\n",
        "    if epsilon > min_epsilon:\n",
        "        epsilon *= epsilon_decay\n",
        "\n",
        "# Evaluación del modelo\n",
        "def find_path(maze, start, goal):\n",
        "    current_position = start\n",
        "    path = [current_position]\n",
        "    while current_position != goal:\n",
        "        action_index = np.argmax(q_table[current_position[0], current_position[1], :])\n",
        "        action = actions[action_index]\n",
        "        current_position = (\n",
        "            current_position[0] + action_map[action][0],\n",
        "            current_position[1] + action_map[action][1]\n",
        "        )\n",
        "        path.append(current_position)\n",
        "        if len(path) > 1000:  # Limitar en caso de bucle infinito\n",
        "            break\n",
        "    return path\n",
        "\n",
        "# Generar camino\n",
        "start_position = (0, 0)\n",
        "while maze[start_position] == 1:\n",
        "    start_position = (np.random.randint(maze_size), np.random.randint(maze_size))\n",
        "\n",
        "path = find_path(maze, start_position, goal_position)\n",
        "\n",
        "# Mostrar laberinto y camino\n",
        "def plot_maze(maze, path):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(maze, cmap=\"binary\")\n",
        "    x, y = zip(*path)\n",
        "    plt.plot(y, x, color=\"red\", linewidth=2)\n",
        "    plt.scatter([goal_position[1]], [goal_position[0]], color=\"green\", label=\"Goal\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_maze(maze, path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6e1YGp27mGnr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}